# PDMBench Hyperparameter Search Spaces
# This file defines search spaces for hyperparameter tuning

# =============================================================================
# Common Hyperparameters (applicable to most models)
# =============================================================================
common:
  learning_rate:
    distribution: log_uniform
    low: 1.0e-5
    high: 1.0e-2

  dropout:
    distribution: uniform
    low: 0.0
    high: 0.5

  batch_size:
    values: [16, 32, 64, 128, 256, 512, 1024]

  train_epochs:
    values: [5, 10, 20, 30, 50]

  patience:
    values: [3, 5, 7, 10]

# =============================================================================
# Architecture Hyperparameters
# =============================================================================
architecture:
  d_model:
    values: [32, 64, 128, 256, 512]

  d_ff:
    values: [128, 256, 512, 1024, 2048]

  n_heads:
    values: [1, 2, 4, 8]

  e_layers:
    values: [1, 2, 3, 4]

  d_layers:
    values: [1, 2]

# =============================================================================
# TimesNet Specific
# =============================================================================
timesnet:
  top_k:
    values: [1, 3, 5, 7]

  num_kernels:
    values: [3, 4, 6, 8]

# =============================================================================
# PatchTST / TimeXer Specific
# =============================================================================
patchtst:
  patch_len:
    values: [8, 12, 16, 24, 32]

# =============================================================================
# Mamba Specific
# =============================================================================
mamba:
  expand:
    values: [1, 2, 4]

  d_conv:
    values: [2, 4, 8]

# =============================================================================
# SegRNN Specific
# =============================================================================
segrnn:
  seg_len:
    values: [24, 48, 96, 192]

# =============================================================================
# Attention Specific
# =============================================================================
attention:
  factor:
    values: [1, 3, 5]

# =============================================================================
# Decomposition Specific
# =============================================================================
decomposition:
  moving_avg:
    values: [13, 25, 37, 49]

  decomp_method:
    values: ["moving_avg", "dft_decomp"]

# =============================================================================
# Preprocessing Hyperparameters
# =============================================================================
preprocessing:
  imputation_method:
    values: ["linear", "spline", "knn", "ffill"]

  normalization_method:
    values: ["standardization", "robust", "minmax", "per_channel"]

# =============================================================================
# Foundation Model Specific
# =============================================================================
chronos:
  chronos_size:
    values: ["tiny", "mini", "small", "base"]

  freeze_backbone:
    values: [true, false]

moirai:
  moirai_size:
    values: ["small", "base", "large"]

  freeze_backbone:
    values: [true, false]

# =============================================================================
# Model-Specific Search Spaces (combined for quick access)
# =============================================================================
model_specific:
  TimesNet:
    include:
      - common
      - architecture
      - timesnet
    defaults:
      d_model: 64
      d_ff: 256
      e_layers: 2
      top_k: 5

  PatchTST:
    include:
      - common
      - architecture
      - patchtst
    defaults:
      d_model: 128
      patch_len: 16
      e_layers: 3

  Transformer:
    include:
      - common
      - architecture
      - attention
    defaults:
      d_model: 512
      n_heads: 8
      e_layers: 2

  Autoformer:
    include:
      - common
      - architecture
      - attention
      - decomposition
    defaults:
      d_model: 512
      moving_avg: 25

  DLinear:
    include:
      - common
    exclude:
      - architecture
    defaults:
      learning_rate: 0.0001

  Mamba:
    include:
      - common
      - mamba
    defaults:
      expand: 2
      d_conv: 4

  SegRNN:
    include:
      - common
      - segrnn
    defaults:
      seg_len: 96

  Chronos:
    include:
      - common
      - chronos
    defaults:
      chronos_size: small
      freeze_backbone: false
      learning_rate: 0.0001

  Moirai:
    include:
      - common
      - moirai
    defaults:
      moirai_size: small
      freeze_backbone: false
      learning_rate: 0.0001

# =============================================================================
# Quick Search Presets
# =============================================================================
presets:
  # Quick search for rapid experimentation
  quick:
    learning_rate:
      values: [0.001, 0.0001]
    batch_size:
      values: [32, 128]
    d_model:
      values: [64, 256]
    e_layers:
      values: [2, 3]

  # Medium search for balanced exploration
  medium:
    learning_rate:
      distribution: log_uniform
      low: 1.0e-4
      high: 1.0e-2
    dropout:
      values: [0.1, 0.2, 0.3]
    batch_size:
      values: [32, 64, 128, 256]
    d_model:
      values: [64, 128, 256]
    e_layers:
      values: [1, 2, 3, 4]

  # Comprehensive search for thorough exploration
  comprehensive:
    learning_rate:
      distribution: log_uniform
      low: 1.0e-5
      high: 1.0e-2
    dropout:
      distribution: uniform
      low: 0.0
      high: 0.5
    batch_size:
      values: [16, 32, 64, 128, 256, 512]
    d_model:
      values: [32, 64, 128, 256, 512]
    d_ff:
      values: [128, 256, 512, 1024, 2048]
    n_heads:
      values: [1, 2, 4, 8]
    e_layers:
      values: [1, 2, 3, 4, 6]

# =============================================================================
# Search Strategy Configuration
# =============================================================================
strategy:
  grid_search:
    description: "Exhaustive search over all combinations"
    max_combinations: 1000  # Warning if exceeded
    parallel_workers: 4

  random_search:
    description: "Random sampling from search space"
    n_trials: 50
    seed: 42
    parallel_workers: 4

  sensitivity_analysis:
    description: "One-factor-at-a-time sensitivity"
    base_config: default  # Reference configuration
    n_samples_per_param: 10
